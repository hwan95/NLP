{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-08T08:44:32.725541Z","iopub.execute_input":"2023-03-08T08:44:32.725946Z","iopub.status.idle":"2023-03-08T08:44:32.758551Z","shell.execute_reply.started":"2023-03-08T08:44:32.725911Z","shell.execute_reply":"2023-03-08T08:44:32.757469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo tar xvf '/kaggle/input/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013.tar.gz'","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:44:32.760657Z","iopub.execute_input":"2023-03-08T08:44:32.761081Z","iopub.status.idle":"2023-03-08T08:44:38.429807Z","shell.execute_reply.started":"2023-03-08T08:44:32.761040Z","shell.execute_reply":"2023-03-08T08:44:38.428557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nimport cv2\nimport sys\nfrom tensorflow.keras.models import load_model \nimport matplotlib.pyplot as plt\nfrom keras.applications.vgg16 import VGG16","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:44:38.432509Z","iopub.execute_input":"2023-03-08T08:44:38.434042Z","iopub.status.idle":"2023-03-08T08:44:47.802777Z","shell.execute_reply.started":"2023-03-08T08:44:38.433991Z","shell.execute_reply":"2023-03-08T08:44:47.801541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/working/fer2013/fer2013.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:44:47.807700Z","iopub.execute_input":"2023-03-08T08:44:47.810862Z","iopub.status.idle":"2023-03-08T08:44:50.315074Z","shell.execute_reply.started":"2023-03-08T08:44:47.810815Z","shell.execute_reply":"2023-03-08T08:44:50.313811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images = data['pixels'].apply(lambda x: np.array(x.split(), dtype='float32'))\nimages = np.stack(images.values)\nimages = images.reshape(images.shape[0], 48, 48, 1)\ncolor_images = []\nfor img in images:\n    color_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    color_images.append(color_img)\n\ncolor_images = np.array(color_images)\nlabels = data['emotion']","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:44:50.318689Z","iopub.execute_input":"2023-03-08T08:44:50.319212Z","iopub.status.idle":"2023-03-08T08:45:02.314445Z","shell.execute_reply.started":"2023-03-08T08:44:50.319172Z","shell.execute_reply":"2023-03-08T08:45:02.313227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train / test data split 분할\ntrain_images, test_images, train_labels, test_labels = train_test_split(color_images, labels, test_size=0.1, stratify=labels)\ntrain_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.1, stratify=train_labels)\n\n# 라벨 one-hot encoding\nnum_classes = 7\ntrain_labels = to_categorical(train_labels, num_classes)\nval_labels = to_categorical(val_labels, num_classes)\ntest_labels = to_categorical(test_labels, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:45:02.316370Z","iopub.execute_input":"2023-03-08T08:45:02.316854Z","iopub.status.idle":"2023-03-08T08:45:02.875081Z","shell.execute_reply.started":"2023-03-08T08:45:02.316805Z","shell.execute_reply":"2023-03-08T08:45:02.873991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\n\nvgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:45:02.876687Z","iopub.execute_input":"2023-03-08T08:45:02.877559Z","iopub.status.idle":"2023-03-08T08:45:07.378106Z","shell.execute_reply.started":"2023-03-08T08:45:02.877519Z","shell.execute_reply":"2023-03-08T08:45:07.376998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 모델 구현\nmodel = Sequential()\n\n# model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n# model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\n# model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.25))\nmodel.add(vgg16_model)\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n# 컴파일\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:45:07.379665Z","iopub.execute_input":"2023-03-08T08:45:07.380422Z","iopub.status.idle":"2023-03-08T08:45:07.524218Z","shell.execute_reply.started":"2023-03-08T08:45:07.380377Z","shell.execute_reply":"2023-03-08T08:45:07.523341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nMODEL_DIR ='./model/'\n\nif not os.path.exists(MODEL_DIR):\n  os.mkdir(MODEL_DIR)\n\nmodelpath  = './model/{epoch:2d}-{val_loss:.4f}.hdf5'","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:45:07.525345Z","iopub.execute_input":"2023-03-08T08:45:07.525699Z","iopub.status.idle":"2023-03-08T08:45:07.533360Z","shell.execute_reply.started":"2023-03-08T08:45:07.525662Z","shell.execute_reply":"2023-03-08T08:45:07.532516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_loss', patience= 5)\n\n\ncheckpoint = keras.callbacks.ModelCheckpoint(filepath = modelpath,\n                                             monitor = 'val_loss',\n                                             verbos = 1,\n                                             save_best_only = True)\n\nbatch_size = 256\nepochs = 300\n# history = model.fit(train_set, train_labels,\n#                     batch_size=batch_size, \n#                     epochs=epochs, \n#                     validation_data=(val_images, val_LABEL))\nhistory = model.fit(train_images, train_labels,\n                    batch_size=batch_size, \n                    epochs=epochs, \n                    validation_data=(val_images, val_labels), \n                    callbacks=[early_stopping, checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-03-08T08:45:07.534913Z","iopub.execute_input":"2023-03-08T08:45:07.535307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 평가\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\nprint('Test accuracy:', test_acc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}